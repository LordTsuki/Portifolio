{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from seaborn) (2.0.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sklearn in /home/tsuki/Documents/Portifolio/Python/.venv/lib/python3.11/site-packages (0.0.post5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn\n",
    "%pip install sklearn\n",
    "%pip install xgboost imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tqdm\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./train.csv\")\n",
    "df_train = pd.read_csv(\"./train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm = RandomUnderSampler()\n",
    "X, Y = rdm.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X, Y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./test.csv\")\n",
    "train = pd.read_csv(\"./train.csv\")\n",
    "combine = [train, test]\n",
    "print('Train columns:', train.columns.tolist())\n",
    "print('Test columns:', test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()\n",
    "print('_'*40)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train, col='Survived', row='Pclass', aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train, row='Embarked', aspect=1.6)\n",
    "grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train, row='Embarked', col='Survived', aspect=1.6)\n",
    "grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before\", train.shape, test.shape, combine[0].shape, combine[1].shape)\n",
    "train = train.drop(['Ticket', 'Cabin'], axis = 1)\n",
    "test = test.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train, test]\n",
    "\n",
    "\"After\", train.shape, test.shape, combine[0].shape, combine[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "pd.crosstab(train['Title'], train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Name', 'PassengerId'], axis=1)\n",
    "test = test.drop(['Name'], axis=1)\n",
    "combine = [train, test]\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map({'female': 1,'male': 0 }).astype(int)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train, row='Pclass', col='Sex', aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "guess_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "            age_guess = guess_df.median()\n",
    "            guess_ages[i, j] = int(age_guess/0.5 + 0.5) * 0.5\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[(dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1), 'Age'] = guess_ages[i, j]\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['AgeBand'] = pd.cut(train['Age'], 5)\n",
    "train[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[dataset['Age'] > 64,'Age']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['AgeBand'], axis = 1)\n",
    "combine = [train, test]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_fare = np.zeros((2,3))\n",
    "guess_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Fare'].dropna()\n",
    "            fare_guess = guess.median()\n",
    "            guess_fare[i, j] = int(fare_guess/0.5 + 0.5) * 0.5\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[(dataset.Fare.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1), 'Fare'] = guess_fare[i, j]\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FareBand'] = pd.cut(train['Fare'], 5)\n",
    "train[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[dataset['Fare'] <= 102.4, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 102.4) & (dataset['Fare'] <= 204.8), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 204.8) & (dataset['Fare'] <= 307.2), 'Fare'] = 2\n",
    "    dataset.loc[(dataset['Fare'] > 307.2) & (dataset['Fare'] <= 409.6), 'Fare'] = 3\n",
    "    dataset.loc[dataset['Fare'] > 409.6,'Fare']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['FareBand'], axis = 1)\n",
    "combine = [train, test]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_embarked = np.zeros((2,3))\n",
    "guess_embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[dataset['Embarked'] == 'S', 'Embarked'] = 0\n",
    "    dataset.loc[dataset['Embarked'] == 'C', 'Embarked'] = 1\n",
    "    dataset.loc[dataset['Embarked'] == 'Q', 'Embarked'] = 2\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[dataset['Pclass'] == None, 'Pclass'] = 3\n",
    "    dataset.loc[dataset['Sex'] == None, 'Sex'] = rnd.randint(0, 1)\n",
    "    dataset.loc[dataset['Age'] == None, 'Age'] = rnd.randint(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'] = train['Embarked'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['Survived'])\n",
    "Y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(0, 100):\n",
    "    j = rnd.randint(1, 100)\n",
    "    k = rnd.randint(1, 100)\n",
    "    model_rf = RandomForestClassifier(random_state=i, max_depth = j, n_estimators = k)\n",
    "    result.append([cross_val_score(model_rf, X, Y, cv=5), j, k])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.73743017, 0.81460674, 0.80898876, 0.80898876, 0.85955056]), random_state=97, max_depth=5, n_estimators=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(0, 100):\n",
    "    j = rnd.randint(1, 100)\n",
    "    k = rnd.randint(1, 100)\n",
    "    model_rf = DecisionTreeClassifier(random_state= i, splitter = \"best\", max_depth = j)\n",
    "    result.append([cross_val_score(model_rf, X, Y, cv=5), j, k])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.81564246, 0.8258427 , 0.8258427 , 0.79213483, 0.85393258]), random_state=64, max_depth=4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = []\n",
    "for i in range(0, 100):\n",
    "    j = rnd.randint(1, 100)\n",
    "    k = rnd.randint(1, 100)\n",
    "    model_rf = MLPClassifier(random_state=i, hidden_layer_sizes=950, max_iter=1000)\n",
    "    result.append([cross_val_score(model_rf, X, Y, cv=5), j, k])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.81005587, 0.83707865, 0.84269663, 0.80898876, 0.88764045]) random_state=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=[\"Survived\"], axis=1)\n",
    "Y = train_data[\"Survived\"]\n",
    "rdm = RandomUnderSampler()\n",
    "X, Y = rdm.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"Survived\"], axis=1)\n",
    "Y_train = train[\"Survived\"]\n",
    "X_test = test.drop(columns=[\"PassengerId\"], axis=1).copy()\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "logreg.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = pd.DataFrame(train.columns.delete(0))\n",
    "coeff.columns = ['Feature']\n",
    "coeff[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "coeff.sort_values(by='Correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "svc.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 100, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    Y_pred = knn.predict(X_test)\n",
    "    knn.score(X_train, Y_train)\n",
    "    result.append([knn.score(X_train, Y_train), i])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "gaussian.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "perceptron.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, Y_train)\n",
    "Y_pred = linear_svc.predict(X_test)\n",
    "linear_svc.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = linear_svc.predict(X_test)\n",
    "sgd.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "decision_tree.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, Y_train)X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, Y_train)\n",
    "Y_pred = mlp.predict(X_test)\n",
    "mlp.score(X_train, Y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j = 1\n",
    "k = 1\n",
    "result = []\n",
    "for i in range(1, 100):\n",
    "    random_forest = RandomForestClassifier(n_estimators = i, max_depth=j, random_state=k)\n",
    "    random_forest.fit(X_train, Y_train)\n",
    "    Y_pred = random_forest.predict(X_test)\n",
    "    random_forest.score(X_train, Y_train)\n",
    "    for j in range(1, 100):\n",
    "        random_forest = RandomForestClassifier(n_estimators = i, max_depth=j, random_state=k)\n",
    "        random_forest.fit(X_train, Y_train)\n",
    "        Y_pred = random_forest.predict(X_test)\n",
    "        random_forest.score(X_train, Y_train)\n",
    "        for  k in range(1, 100):\n",
    "            random_forest = RandomForestClassifier(n_estimators = i, max_depth=j, random_state=k)\n",
    "            random_forest.fit(X_train, Y_train)\n",
    "            Y_pred = random_forest.predict(X_test)\n",
    "            random_forest.score(X_train, Y_train)\n",
    "    result = ([random_forest.score(X_train, Y_train), j, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_svc = svc.score(X_train, Y_train)\n",
    "acc_knn = knn.score(X_train, Y_train)\n",
    "acc_log = logreg.score(X_train, Y_train)\n",
    "acc_rf = random_forest.score(X_train, Y_train)\n",
    "acc_gaussian = gaussian.score(X_train, Y_train)\n",
    "acc_perceptron = perceptron.score(X_train, Y_train)\n",
    "acc_sgd = sgd.score(X_train, Y_train)\n",
    "acc_linear = linear_svc.score(X_train, Y_train)\n",
    "acc_dt = decision_tree.score(X_train, Y_train)\n",
    "acc_mlp = mlp.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', 'Random Forest', 'Naive Bayes', 'Perceptron', 'Stochastic Gradient Decent', 'Linear SVC', 'Decision Tree', 'MLP'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, acc_rf, acc_gaussian, acc_perceptron, acc_sgd, acc_linear, acc_dt, acc_mlp]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": Y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"./New_Dataset\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
